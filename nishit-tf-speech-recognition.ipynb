{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os.path import isdir, join\nfrom pathlib import Path\nimport pandas as pd\nimport tensorflow as tf\n# Math\nimport numpy as np\nfrom scipy.fftpack import fft\nfrom scipy import signal\nfrom scipy.io import wavfile\nimport librosa\n\nfrom sklearn.decomposition import PCA\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport IPython.display as ipd\nimport librosa.display\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport pandas as pd\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport librosa   #for audio processing\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.io import wavfile #for audio processing\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt-get install -y p7zip-full\n!7z x ../input/tensorflow-speech-recognition-challenge/train.7z\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_audio_path = 'train/audio/'\nprint(os.listdir(train_audio_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dirs = [f for f in os.listdir(train_audio_path) if isdir(join(train_audio_path, f))]\ndirs.sort()\nprint('Number of labels: ' + str(len(dirs[1:])))\nprint(dirs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=os.listdir(train_audio_path)\n\n#find count of each label and plot bar graph\nno_of_recordings=[]\nfor label in labels:\n    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n    no_of_recordings.append(len(waves))\n    \n#plot\nplt.figure(figsize=(30,5))\nindex = np.arange(len(labels))\nplt.bar(index, no_of_recordings)\nplt.xlabel('Commands', fontsize=12)\nplt.ylabel('No of recordings', fontsize=12)\nplt.xticks(index, labels, fontsize=15, rotation=60)\nplt.title('No. of recordings for each command')\nplt.show()\n\nlabels=[\"up\", \"down\", \"left\", \"right\", \"stop\", \"go\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_wave = []\nall_label = []\nfor label in labels:\n    print(label)\n    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n    for wav in waves:\n        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n        samples = librosa.resample(samples, sample_rate, 8000)\n        if(len(samples)== 8000) : \n            all_wave.append(samples)\n            all_label.append(label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def log_specgram(audio, sample_rate, window_size=20,\n                 step_size=10, eps=1e-10):\n    nperseg = int(round(window_size * sample_rate / 1e3))\n    noverlap = int(round(step_size * sample_rate / 1e3))\n    freqs, times, spec = signal.spectrogram(audio,\n                                    fs=sample_rate,\n                                    window='hann',\n                                    nperseg=nperseg,\n                                    noverlap=noverlap,\n                                    detrend=False)\n    return freqs, times, np.log(spec.T.astype(np.float32) + eps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = '/yes/0a7c2a8d_nohash_0.wav'\nfrom scipy.io import wavfile\nsample_rate, samples = wavfile.read(str(train_audio_path) + filename)\nfreqs, times, spectrogram = log_specgram(samples, sample_rate)\n\nfig = plt.figure(figsize=(14, 8))\nax1 = fig.add_subplot(211)\nax1.set_title('Raw wave of ' + filename)\nax1.set_ylabel('Amplitude')\nax1.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)\n\nax2 = fig.add_subplot(212)\nax2.imshow(spectrogram.T, aspect='auto', origin='lower', \n           extent=[times.min(), times.max(), freqs.min(), freqs.max()])\nax2.set_yticks(freqs[::16])\nax2.set_xticks(times[::16])\nax2.set_title('Spectrogram of ' + filename)\nax2.set_ylabel('Freqs in Hz')\nax2.set_xlabel('Seconds')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def list_wavs_fname(dirpath, ext='wav'):\n    print(dirpath)\n    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n    pat = r'.+/(\\w+)/\\w+\\.' + ext + '$'\n    labels = []\n    for fpath in fpaths:\n        r = re.match(pat, fpath)\n        if r:\n            labels.append(r.group(1))\n    pat = r'.+/(\\w+\\.' + ext + ')$'\n    fnames = []\n    for fpath in fpaths:\n        r = re.match(pat, fpath)\n        if r:\n            fnames.append(r.group(1))\n    return labels, fnames\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels, fnames = list_wavs_fname(train_audio_path)\n\nnew_sample_rate = 8000\ny_train = []\nx_train = []\nfor label, fname in zip(labels, fnames):\n    sample_rate, samples = wavfile.read(os.path.join(train_audio_path, label, fname))\n    samples = pad_audio(samples)\n    if len(samples) > 8000:\n        n_samples = chop_audio(samples)\n    else: n_samples = [samples]\n    for samples in n_samples:\n        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n        y_train.append(label)\n        x_train.append(specgram)\nx_train = np.array(x_train)\n# x_train = x_train.reshape(tuple(list(x_train.shape) + [1]))\ny_train = label_transform(y_train)\nlabel_index = y_train.columns.values\ny_train = y_train.values\ny_train = np.array(y_train)\ndel labels, fnames\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duration_of_recordings=[]\nfor label in labels:\n    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n    for wav in waves:\n        sample_rate, samples = wavfile.read(train_audio_path + '/' + label + '/' + wav)\n        duration_of_recordings.append(float(len(samples)/sample_rate))\n    \nplt.hist(np.array(duration_of_recordings))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"L = 8000\ndef pad_audio(samples):\n    if len(samples) >= L:\n        return samples\n    else:\n        return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"po=pad_audio(samples)\nplr=[]\nplr.append(float(len(po)/sample_rate))\nplt.hist(plr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function, division\nfrom builtins import range, input\n\n\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom glob import glob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [224, 224] \n\n# add preprocessing layer to the front of VGG\nvgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n# don't train existing weights\nfor layer in vgg.layers:\n    layer.trainable = False\nfolders=glob('train/audio/')\n# our layers\nx = Flatten()(vgg.output)\n# x = Dense(1000, activation='relu')(x)\nprediction = Dense(len(labels), activation='softmax')(x)\n\n\n# create a model object\nmodel = Model(inputs=vgg.input, outputs=prediction)\n\n# view the structure of the model\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny=le.fit_transform(all_label)\nclasses= list(le.classes_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import np_utils\ny=np_utils.to_categorical(y, num_classes=len(labels))\nall_wave = np.array(all_wave).reshape(-1,8000,1)\nfrom sklearn.model_selection import train_test_split\nx_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nmodel.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.00001) \nmc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nhistory=model.fit(x_tr, y_tr ,epochs=200, callbacks=[es,mc], batch_size=32, validation_data=(x_val,y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}